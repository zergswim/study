{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2조_3주차_미션 제리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP867L8oJgc0c8e2dzCN+aY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zergswim/study/blob/AI_basic/2%EC%A1%B0_3%EC%A3%BC%EC%B0%A8_%EB%AF%B8%EC%85%98_%EC%A0%9C%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4zWep0SMPhn",
        "outputId": "be4e4439-c161-4d5b-c4a4-3ff5697c62dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4484815  0.43384555]\n",
            " [0.50010039 0.64178167]\n",
            " [0.26998801 0.3121345 ]\n",
            " [0.69545142 0.66366724]\n",
            " [0.59306623 0.65242754]] (5, 2)\n"
          ]
        }
      ],
      "source": [
        "#Q1\n",
        "import numpy as np\n",
        "\n",
        "arr1 = np.random.rand(5,3)\n",
        "arr2 = np.random.rand(3,2)\n",
        "\n",
        "dot = arr1 @ arr2 \n",
        "#dot = arr1.dot(arr2)\n",
        "\n",
        "print(dot, dot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "arr1 = np.array([[5,7],[9,11]], float)\n",
        "arr2 = np.array([[2,4],[6,8]], float)\n",
        "\n",
        "concat1 = np.vstack((arr1, arr2))\n",
        "concat2 = np.hstack((arr1, arr2))\n",
        "#concat1 = np.concatenate((arr1, arr2), axis=0)\n",
        "#concat2 = np.concatenate((arr1, arr2), axis=1)\n",
        "\n",
        "print(concat1)\n",
        "print(concat2)"
      ],
      "metadata": {
        "id": "Vt_slDCZjhbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2ad47e-b261-48e7-c6b9-f469b7bd6ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.  7.]\n",
            " [ 9. 11.]\n",
            " [ 2.  4.]\n",
            " [ 6.  8.]]\n",
            "[[ 5.  7.  2.  4.]\n",
            " [ 9. 11.  6.  8.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "              [10., 20., 30., 40., 50., 60.]])\n",
        "\n",
        "x_train = xy[0]\n",
        "y_train = xy[1]\n",
        "\n",
        "print(x_train, x_train.shape)\n",
        "print(y_train, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hQ3Mdm455uu",
        "outputId": "1013b99e-11dc-47ed-8488-7d5d7b063123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6.] (6,)\n",
            "[10. 20. 30. 40. 50. 60.] (6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4\n",
        "beta_gd = np.random.rand(1)\n",
        "bais = np.random.rand(1)\n",
        "\n",
        "print(beta_gd, bais)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rtKJJKQ7gFU",
        "outputId": "6c4e2225-f9be-4f97-99d7-df4cb2f58158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.83914004] [0.90195064]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "import numpy as np\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "              [3., 6., 9., 12., 15., 18.]])\n",
        "\n",
        "#-1:size를 기반으로 row 개수 산정, 1차원 행렬변환\n",
        "x_train = xy[0].reshape(-1,1)\n",
        "y_train = xy[1].reshape(-1,1)\n",
        "\n",
        "beta_gd = np.random.rand(1).reshape(-1,1)\n",
        "bais = np.random.rand(1)\n",
        "learning_rate = 0.001\n",
        "\n",
        "import math\n",
        "def l2norm(x):\n",
        "  x_norm = x * x\n",
        "  x_norm = np.sum(x_norm)\n",
        "  x_norm = np.sqrt(x_norm)\n",
        "  return x_norm\n",
        "\n",
        "for i in range(1000+1):\n",
        "  error = y_train - (x_train @ beta_gd)\n",
        "  grad = - x_train.T @ error \n",
        "  beta_gd = beta_gd - learning_rate * grad\n",
        "  #여기서 bais 는 필요가 없는 것일까?\n",
        "  #bais = bais - learning_rate * grad\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(\"Epoch ({:10d}/1000) error : {:10f} grad : {:10f} beta_gd : {:10f} bais : {:10f}\".format(i, l2norm(error), l2norm(grad), l2norm(beta_gd), l2norm(bais)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQ9QbG49IwO",
        "outputId": "f7a0665c-f5ad-4f3a-d865-fcec737df355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (         0/1000) error :  21.438727 grad : 204.512418 beta_gd :   0.957123 bais :   0.538997\n",
            "Epoch (       100/1000) error :   0.001540 grad :   0.014693 beta_gd :   2.999853 bais :   0.538997\n",
            "Epoch (       200/1000) error :   0.000000 grad :   0.000001 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       300/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       400/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       500/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       600/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       700/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       800/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (       900/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n",
            "Epoch (      1000/1000) error :   0.000000 grad :   0.000000 beta_gd :   3.000000 bais :   0.538997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#응용 다차원 배열 테스트..., beta_gd 를 다차원으로 하는 방법은?? , W.T * X + b = Y 형으로 고려?\n",
        "import numpy as np\n",
        "SIZE = 180 #다차원 크기 지정\n",
        "x_train = np.random.rand(SIZE, 6)\n",
        "y_train = (np.random.rand(6)*100).reshape(-1,1)\n",
        "\n",
        "beta_gd = np.random.rand(1).reshape(-1,1)\n",
        "bais = np.random.rand(1)\n",
        "learning_rate = 0.001\n",
        "\n",
        "import math\n",
        "def l2norm(x):\n",
        "  x_norm = x * x\n",
        "  x_norm = np.sum(x_norm)\n",
        "  x_norm = np.sqrt(x_norm)\n",
        "  return x_norm\n",
        "\n",
        "import random\n",
        "for i in range(1000+1):\n",
        "  r = random.randrange(1, SIZE)\n",
        "  x_train_one = x_train[r].reshape(-1,1)\n",
        "\n",
        "  error = y_train - (x_train_one @ beta_gd)\n",
        "  grad = - x_train_one.T @ error\n",
        "  beta_gd = beta_gd - learning_rate * grad\n",
        "  #bais = bais - learning_rate * grad\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(\"Epoch ({:10d}/1000) error : {:10f} grad : {:10f} beta_gd : {:10f} bais : {:10f}\".format(i, l2norm(error), l2norm(grad), l2norm(beta_gd), l2norm(bais)))\n",
        "\n",
        "print(\"--NEXT--\")\n",
        "\n",
        "for i in range(10000+1):\n",
        "  pred = x_train_one * beta_gd + beta_gd\n",
        "  error = ((pred - y_train) ** 2).mean()\n",
        "\n",
        "  gd_w = ((pred - y_train) * 2 * x_train_one).mean() #why?\n",
        "  gd_b = ((pred - y_train) * 2).mean() #why?\n",
        "\n",
        "  beta_gd = beta_gd - learning_rate * grad\n",
        "  bais = bais - learning_rate * grad\n",
        "\n",
        "  if i%1000 == 0:\n",
        "    print(\"Epoch ({:10d}/1000) error : {:10f} grad_w : {:10f} grad_b : {:10f} beta_gd : {:10f} bais : {:10f}\".format(i, error, gd_w, gd_b, beta_gd.item(), bais.item()))"
      ],
      "metadata": {
        "id": "6vcx5zvjfV5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd765daa-ebc6-4a56-99dc-87f77bce6b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (         0/1000) error : 167.531796 grad : 100.511503 beta_gd :   0.762243 bais :   0.069691\n",
            "Epoch (       100/1000) error : 144.597632 grad : 204.425343 beta_gd :  16.280070 bais :   0.069691\n",
            "Epoch (       200/1000) error : 157.946427 grad :  34.214465 beta_gd :  29.075502 bais :   0.069691\n",
            "Epoch (       300/1000) error : 133.072224 grad : 101.574633 beta_gd :  39.899602 bais :   0.069691\n",
            "Epoch (       400/1000) error : 130.055234 grad :  81.365680 beta_gd :  48.517568 bais :   0.069691\n",
            "Epoch (       500/1000) error : 126.448427 grad :  10.691495 beta_gd :  55.583464 bais :   0.069691\n",
            "Epoch (       600/1000) error : 113.646029 grad :  73.090685 beta_gd :  61.154934 bais :   0.069691\n",
            "Epoch (       700/1000) error : 123.493109 grad :  32.905482 beta_gd :  65.976548 bais :   0.069691\n",
            "Epoch (       800/1000) error : 109.100635 grad :  51.591457 beta_gd :  69.848787 bais :   0.069691\n",
            "Epoch (       900/1000) error :  82.810715 grad :  55.137455 beta_gd :  72.875175 bais :   0.069691\n",
            "Epoch (      1000/1000) error : 132.261533 grad :  21.290152 beta_gd :  75.611041 bais :   0.069691\n",
            "--NEXT--\n",
            "Epoch (         0/1000) error : 4057.743860 grad_w :  50.739423 grad_b :  90.719628 beta_gd :  75.632331 bais :   0.090981\n",
            "Epoch (      1000/1000) error : 7968.367133 grad_w :  76.322975 grad_b : 149.582503 beta_gd :  96.922483 bais :  21.381133\n",
            "Epoch (      2000/1000) error : 13676.867625 grad_w : 101.906526 grad_b : 208.445378 beta_gd : 118.212635 bais :  42.671285\n",
            "Epoch (      3000/1000) error : 21183.245337 grad_w : 127.490077 grad_b : 267.308253 beta_gd : 139.502786 bais :  63.961436\n",
            "Epoch (      4000/1000) error : 30487.500268 grad_w : 153.073628 grad_b : 326.171128 beta_gd : 160.792938 bais :  85.251588\n",
            "Epoch (      5000/1000) error : 41589.632418 grad_w : 178.657179 grad_b : 385.034003 beta_gd : 182.083090 bais : 106.541740\n",
            "Epoch (      6000/1000) error : 54489.641788 grad_w : 204.240731 grad_b : 443.896877 beta_gd : 203.373241 bais : 127.831891\n",
            "Epoch (      7000/1000) error : 69187.528377 grad_w : 229.824282 grad_b : 502.759752 beta_gd : 224.663393 bais : 149.122043\n",
            "Epoch (      8000/1000) error : 85683.292186 grad_w : 255.407833 grad_b : 561.622627 beta_gd : 245.953545 bais : 170.412195\n",
            "Epoch (      9000/1000) error : 103976.933214 grad_w : 280.991384 grad_b : 620.485502 beta_gd : 267.243696 bais : 191.702346\n",
            "Epoch (     10000/1000) error : 124068.451462 grad_w : 306.574936 grad_b : 679.348377 beta_gd : 288.533848 bais : 212.992498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#강의 예제.. 테스트용\n",
        "X = np.array([[1,1], [1,2], [2,2], [2,3]])\n",
        "y = np.dot(X, np.array([1,2])) * 3#X @ np.array([1,2]) * 3\n",
        "\n",
        "beta_gd = np.random.rand(2,4) #np.array([[10.1, 15.1, -6.5, 1]]) #np.random.rand(3)\n",
        "X_ = np.array([np.append(x,[1]) for x in X]) #intercept 항 추가?\n",
        "\n",
        "print(X_.shape, y, beta_gd.shape)\n",
        "\n",
        "for t in range(5000):\n",
        "  error = y - X @ beta_gd\n",
        "  grad = -np.transpose(X) @ error\n",
        "  beta_gd = beta_gd - 0.01 * grad\n",
        "\n",
        "  if(t%100 == 0):\n",
        "    print(\"{:10f}, {:10f}, {:10f}\".format(l2norm(error), l2norm(grad), l2norm(beta_gd)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ix_aoLc91gC",
        "outputId": "91dd3f69-5718-4edc-86c0-ea4efe6a4632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3) [ 9 15 18 24] (2, 4)\n",
            " 61.820229, 304.966643,   4.723791\n",
            " 21.089640,   1.575384,  12.837783\n",
            " 21.008270,   1.056724,  13.143576\n",
            " 20.971556,   0.708821,  13.415137\n",
            " 20.955016,   0.475457,  13.625380\n",
            " 20.947570,   0.318924,  13.778446\n",
            " 20.944218,   0.213925,  13.886350\n",
            " 20.942710,   0.143495,  13.961026\n",
            " 20.942032,   0.096252,  14.012133\n",
            " 20.941727,   0.064563,  14.046866\n",
            " 20.941589,   0.043307,  14.070365\n",
            " 20.941527,   0.029049,  14.086218\n",
            " 20.941500,   0.019486,  14.096893\n",
            " 20.941487,   0.013070,  14.104071\n",
            " 20.941482,   0.008767,  14.108894\n",
            " 20.941479,   0.005881,  14.112133\n",
            " 20.941478,   0.003945,  14.114307\n",
            " 20.941477,   0.002646,  14.115766\n",
            " 20.941477,   0.001775,  14.116745\n",
            " 20.941477,   0.001191,  14.117402\n",
            " 20.941477,   0.000799,  14.117843\n",
            " 20.941477,   0.000536,  14.118138\n",
            " 20.941477,   0.000359,  14.118337\n",
            " 20.941477,   0.000241,  14.118470\n",
            " 20.941477,   0.000162,  14.118559\n",
            " 20.941477,   0.000108,  14.118619\n",
            " 20.941477,   0.000073,  14.118659\n",
            " 20.941477,   0.000049,  14.118686\n",
            " 20.941477,   0.000033,  14.118704\n",
            " 20.941477,   0.000022,  14.118716\n",
            " 20.941477,   0.000015,  14.118724\n",
            " 20.941477,   0.000010,  14.118730\n",
            " 20.941477,   0.000007,  14.118733\n",
            " 20.941477,   0.000004,  14.118736\n",
            " 20.941477,   0.000003,  14.118737\n",
            " 20.941477,   0.000002,  14.118739\n",
            " 20.941477,   0.000001,  14.118739\n",
            " 20.941477,   0.000001,  14.118740\n",
            " 20.941477,   0.000001,  14.118740\n",
            " 20.941477,   0.000000,  14.118740\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n"
          ]
        }
      ]
    }
  ]
}