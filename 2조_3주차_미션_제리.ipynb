{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2조_3주차_미션 제리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMoBMm3L1Aj2XOncqP1imd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zergswim/study/blob/AI_basic/2%EC%A1%B0_3%EC%A3%BC%EC%B0%A8_%EB%AF%B8%EC%85%98_%EC%A0%9C%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o4zWep0SMPhn"
      },
      "outputs": [],
      "source": [
        "#Q1\n",
        "import numpy as np\n",
        "\n",
        "arr1 = np.random.rand(5,3)\n",
        "arr2 = np.random.rand(3,2)\n",
        "\n",
        "dot = arr1 @ arr2 #행렬곱\n",
        "#dot = arr1.dot(arr2) #내적\n",
        "\n",
        "#print(dot, dot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "arr1 = np.array([[5,7],[9,11]], float)\n",
        "arr2 = np.array([[2,4],[6,8]], float)\n",
        "\n",
        "concat1 = np.vstack((arr1, arr2))\n",
        "concat2 = np.hstack((arr1, arr2))\n",
        "#concat1 = np.concatenate((arr1, arr2), axis=0)\n",
        "#concat2 = np.concatenate((arr1, arr2), axis=1)\n",
        "\n",
        "print(concat1)\n",
        "print(concat2)"
      ],
      "metadata": {
        "id": "Vt_slDCZjhbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2ad47e-b261-48e7-c6b9-f469b7bd6ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.  7.]\n",
            " [ 9. 11.]\n",
            " [ 2.  4.]\n",
            " [ 6.  8.]]\n",
            "[[ 5.  7.  2.  4.]\n",
            " [ 9. 11.  6.  8.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "import numpy as np\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "              [10., 20., 30., 40., 50., 60.]])\n",
        "\n",
        "x_train = xy[0]\n",
        "y_train = xy[1]\n",
        "\n",
        "print(x_train, x_train.shape)\n",
        "print(y_train, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hQ3Mdm455uu",
        "outputId": "f650521f-90f8-48c0-e049-fdc35f6aaf90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6.] (6,)\n",
            "[10. 20. 30. 40. 50. 60.] (6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4\n",
        "beta_gd = np.random.rand(1)\n",
        "bais = np.random.rand(1)\n",
        "\n",
        "print(beta_gd, bais)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rtKJJKQ7gFU",
        "outputId": "90c07849-daa1-4c40-e2cb-34da6adbd409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.64644345] [0.84463012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "import numpy as np\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "              [3., 6., 9., 12., 15., 18.]])\n",
        "\n",
        "#-1:size를 기반으로 row 개수 산정, 1차원 행렬변환\n",
        "x_train = xy[0].reshape(-1,1)\n",
        "y_train = xy[1].reshape(-1,1)\n",
        "\n",
        "beta_gd = np.random.rand(1).reshape(-1,1)\n",
        "bais = np.random.rand(1)\n",
        "learning_rate = 0.001\n",
        "\n",
        "import math\n",
        "def l2norm(x):\n",
        "  x_norm = x * x\n",
        "  x_norm = np.sum(x_norm)\n",
        "  x_norm = np.sqrt(x_norm)\n",
        "  return x_norm\n",
        "\n",
        "for i in range(1000+1):\n",
        "  error = y_train - (x_train @ beta_gd)\n",
        "  grad = - x_train.T @ error + bais\n",
        "  beta_gd = beta_gd - learning_rate * grad\n",
        "  bais = bais - learning_rate * grad\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(\"Epoch ({:10d}/1000) error : {:10f} grad : {:10f} beta_gd : {:10f} bais : {:10f}\".format(i, l2norm(error), l2norm(grad), l2norm(beta_gd), l2norm(bais)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQ9QbG49IwO",
        "outputId": "9abf6aff-355e-482d-aad0-f927620672b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (         0/1000) error :  27.623633 grad : 262.772752 beta_gd :   0.367029 bais :   1.002689\n",
            "Epoch (       100/1000) error :   0.378732 grad :   0.016911 beta_gd :   2.960315 bais :   3.595975\n",
            "Epoch (       200/1000) error :   0.376978 grad :   0.000001 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       300/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       400/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       500/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       600/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       700/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       800/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (       900/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n",
            "Epoch (      1000/1000) error :   0.376978 grad :   0.000000 beta_gd :   2.960482 bais :   3.596142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD 응용 다차원 배열 테스트..., beta_gd 를 다차원으로 하는 방법은?? , W.T * X + b = Y 형으로 고려?\n",
        "import numpy as np\n",
        "SIZE = 180 #다차원 크기 지정\n",
        "x_train = np.random.rand(SIZE, 6)\n",
        "y_train = (np.random.rand(6)*100).reshape(-1,1)\n",
        "\n",
        "beta_gd = np.random.rand(1).reshape(-1,1)\n",
        "bais = np.random.rand(1)\n",
        "learning_rate = 0.001\n",
        "\n",
        "import math\n",
        "def l2norm(x):\n",
        "  x_norm = x * x\n",
        "  x_norm = np.sum(x_norm)\n",
        "  x_norm = np.sqrt(x_norm)\n",
        "  return x_norm\n",
        "\n",
        "import random\n",
        "for i in range(1000+1):\n",
        "  r = random.randrange(1, SIZE)\n",
        "  x_train_one = x_train[r].reshape(-1,1)\n",
        "\n",
        "  #error = y_train - (x_train_one @ beta_gd)\n",
        "  #grad = - x_train_one.T @ error\n",
        "  \n",
        "  error = y_train - (x_train_one @ beta_gd)\n",
        "  grad = - error.T @ x_train_one + bais\n",
        "  beta_gd = beta_gd - learning_rate * grad\n",
        "  bais = bais - learning_rate * grad\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(\"Epoch ({:10d}/1000) error : {:10f} grad : {:10f} beta_gd : {:10f} bais : {:10f}\".format(i, l2norm(error), l2norm(grad), l2norm(beta_gd), l2norm(bais)))\n",
        "\n",
        "print(\"--NEXT--\")\n",
        "\n",
        "for i in range(10000+1):\n",
        "  r = random.randrange(1, SIZE)\n",
        "  x_train_one = x_train[r].reshape(-1,1)\n",
        "\n",
        "  pred = x_train_one * beta_gd + beta_gd\n",
        "  error = ((pred - y_train) ** 2).mean()\n",
        "\n",
        "  gd_w = ((pred - y_train) * 2 * x_train_one).mean() #why?\n",
        "  gd_b = ((pred - y_train) * 2).mean() #why?\n",
        "\n",
        "  beta_gd = beta_gd - learning_rate * grad\n",
        "  bais = bais - learning_rate * grad\n",
        "\n",
        "  if i%1000 == 0:\n",
        "    print(\"Epoch ({:10d}/1000) error : {:10f} grad_w : {:10f} grad_b : {:10f} beta_gd : {:10f} bais : {:10f}\".format(i, error, gd_w, gd_b, beta_gd.item(), bais.item()))"
      ],
      "metadata": {
        "id": "6vcx5zvjfV5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be573085-8c23-41e8-c1a5-9c40b1638a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (         0/1000) error : 136.052229 grad : 132.822946 beta_gd :   0.783683 bais :   0.919961\n",
            "Epoch (       100/1000) error : 123.864807 grad : 114.432185 beta_gd :  12.198477 bais :  12.334755\n",
            "Epoch (       200/1000) error : 105.730999 grad : 133.232092 beta_gd :  20.788866 bais :  20.925144\n",
            "Epoch (       300/1000) error : 117.965267 grad :  26.828319 beta_gd :  27.112351 bais :  27.248629\n",
            "Epoch (       400/1000) error : 108.727155 grad :  40.748446 beta_gd :  31.850495 bais :  31.986773\n",
            "Epoch (       500/1000) error : 106.132350 grad :  32.750659 beta_gd :  35.550247 bais :  35.686525\n",
            "Epoch (       600/1000) error : 114.516707 grad :   5.172427 beta_gd :  37.944711 bais :  38.080989\n",
            "Epoch (       700/1000) error : 103.366676 grad :  24.078347 beta_gd :  40.038198 bais :  40.174475\n",
            "Epoch (       800/1000) error : 100.386185 grad :  42.411151 beta_gd :  41.298079 bais :  41.434357\n",
            "Epoch (       900/1000) error :  90.280507 grad :  21.631513 beta_gd :  42.286291 bais :  42.422569\n",
            "Epoch (      1000/1000) error : 108.095524 grad :   0.851508 beta_gd :  42.932736 bais :  43.069014\n",
            "--NEXT--\n",
            "Epoch (         0/1000) error : 1421.817023 grad_w :  11.745730 grad_b :  20.330520 beta_gd :  42.931885 bais :  43.068163\n",
            "Epoch (      1000/1000) error : 1862.568436 grad_w :  35.043510 grad_b :  38.162396 beta_gd :  42.080377 bais :  42.216655\n",
            "Epoch (      2000/1000) error : 1654.611122 grad_w :  24.060054 grad_b :  29.424940 beta_gd :  41.228869 bais :  41.365147\n",
            "Epoch (      3000/1000) error : 1543.865032 grad_w :  22.592563 grad_b :  28.890387 beta_gd :  40.377361 bais :  40.513639\n",
            "Epoch (      4000/1000) error : 1964.050684 grad_w :  28.255342 grad_b :  12.563757 beta_gd :  39.525854 bais :  39.662131\n",
            "Epoch (      5000/1000) error : 1408.383921 grad_w :  18.354980 grad_b :  23.044577 beta_gd :  38.674346 bais :  38.810623\n",
            "Epoch (      6000/1000) error : 771.033598 grad_w :  -6.278799 grad_b :   6.915216 beta_gd :  37.822838 bais :  37.959116\n",
            "Epoch (      7000/1000) error : 1915.518242 grad_w :  33.587281 grad_b :  21.967657 beta_gd :  36.971330 bais :  37.107608\n",
            "Epoch (      8000/1000) error : 1133.604801 grad_w :  10.605426 grad_b :  15.907570 beta_gd :  36.119822 bais :  36.256100\n",
            "Epoch (      9000/1000) error : 1211.507915 grad_w :   9.827282 grad_b :  12.953054 beta_gd :  35.268314 bais :  35.404592\n",
            "Epoch (     10000/1000) error : 1343.892214 grad_w :  18.433836 grad_b :  21.550859 beta_gd :  34.416807 bais :  34.553084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#강의 예제.. 테스트용\n",
        "X = np.array([[1,1], [1,2], [2,2], [2,3]])\n",
        "y = np.dot(X, np.array([1,2])) * 3#X @ np.array([1,2]) * 3\n",
        "\n",
        "beta_gd = np.random.rand(2,4) #np.array([[10.1, 15.1, -6.5, 1]]) #np.random.rand(3)\n",
        "X_ = np.array([np.append(x,[1]) for x in X]) #intercept 항 추가?\n",
        "\n",
        "print(X_.shape, y, beta_gd.shape)\n",
        "\n",
        "for t in range(5000):\n",
        "  error = y - X @ beta_gd\n",
        "  grad = -np.transpose(X) @ error\n",
        "  beta_gd = beta_gd - 0.01 * grad\n",
        "\n",
        "  if(t%100 == 0):\n",
        "    print(\"{:10f}, {:10f}, {:10f}\".format(l2norm(error), l2norm(grad), l2norm(beta_gd)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ix_aoLc91gC",
        "outputId": "91dd3f69-5718-4edc-86c0-ea4efe6a4632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3) [ 9 15 18 24] (2, 4)\n",
            " 61.820229, 304.966643,   4.723791\n",
            " 21.089640,   1.575384,  12.837783\n",
            " 21.008270,   1.056724,  13.143576\n",
            " 20.971556,   0.708821,  13.415137\n",
            " 20.955016,   0.475457,  13.625380\n",
            " 20.947570,   0.318924,  13.778446\n",
            " 20.944218,   0.213925,  13.886350\n",
            " 20.942710,   0.143495,  13.961026\n",
            " 20.942032,   0.096252,  14.012133\n",
            " 20.941727,   0.064563,  14.046866\n",
            " 20.941589,   0.043307,  14.070365\n",
            " 20.941527,   0.029049,  14.086218\n",
            " 20.941500,   0.019486,  14.096893\n",
            " 20.941487,   0.013070,  14.104071\n",
            " 20.941482,   0.008767,  14.108894\n",
            " 20.941479,   0.005881,  14.112133\n",
            " 20.941478,   0.003945,  14.114307\n",
            " 20.941477,   0.002646,  14.115766\n",
            " 20.941477,   0.001775,  14.116745\n",
            " 20.941477,   0.001191,  14.117402\n",
            " 20.941477,   0.000799,  14.117843\n",
            " 20.941477,   0.000536,  14.118138\n",
            " 20.941477,   0.000359,  14.118337\n",
            " 20.941477,   0.000241,  14.118470\n",
            " 20.941477,   0.000162,  14.118559\n",
            " 20.941477,   0.000108,  14.118619\n",
            " 20.941477,   0.000073,  14.118659\n",
            " 20.941477,   0.000049,  14.118686\n",
            " 20.941477,   0.000033,  14.118704\n",
            " 20.941477,   0.000022,  14.118716\n",
            " 20.941477,   0.000015,  14.118724\n",
            " 20.941477,   0.000010,  14.118730\n",
            " 20.941477,   0.000007,  14.118733\n",
            " 20.941477,   0.000004,  14.118736\n",
            " 20.941477,   0.000003,  14.118737\n",
            " 20.941477,   0.000002,  14.118739\n",
            " 20.941477,   0.000001,  14.118739\n",
            " 20.941477,   0.000001,  14.118740\n",
            " 20.941477,   0.000001,  14.118740\n",
            " 20.941477,   0.000000,  14.118740\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n",
            " 20.941477,   0.000000,  14.118741\n"
          ]
        }
      ]
    }
  ]
}